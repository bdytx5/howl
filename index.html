<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Howl: How to generate a dataset for custom wakeword</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Howl<span id="projectnumber">&#160;1.0</span>
   </div>
   <div id="projectbrief">Wake word detection modeling toolkit for Firefox Voice, supporting open datasets like Speech Commands and Common Voice.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">How to generate a dataset for custom wakeword </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p ><a class="anchor" id="md_howl_dataset_README"></a> Generating a dataset for a custom wakeword requires three steps:</p><ol type="1">
<li>Generating raw audio dataset that howl can load from open datasets</li>
<li>Generate orthographic transcription alignments for each audio file.</li>
<li>Attach the alignment to the raw audio dataset generated in step 1.</li>
</ol>
<p >In the example that follows, we describe the process of generating a dataset for the word, "fire".</p>
<ol type="1">
<li>Download a supported data source. We recommend <a href="https://commonvoice.mozilla.org/">Common Voice</a> for its breadth and free license.</li>
<li>To provide transcription alignment for the data, we use <a href="https://montreal-forced-aligner.readthedocs.io/en/stable/installation.html">Montreal Forced Aligner</a> (MFA) along with an <a href="http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict/cmudict-0.7b">English pronunciation dictionary</a>. We have written a script that download them under the repo <div class="fragment"><div class="line">./download_mfa.sh</div>
</div><!-- fragment --></li>
<li>Create raw audio datasets containing the keyword for howl from open audio datasets: note that 5% is sufficient when generating negative dataset from common-voice dataset <div class="fragment"><div class="line">VOCAB=&#39;[&quot;fire&quot;]&#39; INFERENCE_SEQUENCE=[0] python -m training.run.generate_raw_audio_dataset -i &lt;~/path/to/common-voice&gt; --positive-pct 100 --negative-pct 5</div>
</div><!-- fragment --> This script generate a dataset for fire under <code>datasets</code> directory. fire dataset has two directories, one for positive samples and one for negative samples. Each contains audio files, transcriptions, and json files for training, dev, test set <div class="fragment"><div class="line">datasets/</div>
<div class="line">└── fire</div>
<div class="line">    ├── negative</div>
<div class="line">    │   └── audio</div>
<div class="line">    └── positive</div>
<div class="line">        ├── audio</div>
<div class="line">        ├── metadata-dev.jsonl</div>
<div class="line">        ├── metadata-test.jsonl</div>
<div class="line">        └── metadata-training.jsonl</div>
</div><!-- fragment --> Before the alignment each entry in <code>metadata-*.jsonl</code> only has relative path to the audio file and the transcription <div class="fragment"><div class="line">{&quot;path&quot;: &quot;common_voice_en_19633015.wav&quot;, &quot;phone_strings&quot;: null, &quot;words&quot;: null, &quot;phone_end_timestamps&quot;: null, &quot;end_timestamps&quot;: null, &quot;transcription&quot;: &quot;During World War One, Sasha Chorny served as a private at a field hospital.&quot;}</div>
<div class="line">{&quot;path&quot;: &quot;common_voice_en_19980734.wav&quot;, &quot;phone_strings&quot;: null, &quot;words&quot;: null, &quot;phone_end_timestamps&quot;: null, &quot;end_timestamps&quot;: null, &quot;transcription&quot;: &quot;\&quot;Laura&#39;s world has been jolted.\&quot;&quot;}</div>
<div class="line">{&quot;path&quot;: &quot;common_voice_en_18651632.wav&quot;, &quot;phone_strings&quot;: null, &quot;words&quot;: null, &quot;phone_end_timestamps&quot;: null, &quot;end_timestamps&quot;: null, &quot;transcription&quot;: &quot;If we look after the world and each other.&quot;}</div>
<div class="line">...</div>
</div><!-- fragment --></li>
<li>Next step is to align orthographic transcriptions to the audio using MFA. We only need to process positive samples as we don't need the alignment for the negative samples <div class="fragment"><div class="line">mkdir -p datasets/fire/positive/alignment</div>
<div class="line">pushd montreal-forced-aligner</div>
<div class="line">./bin/mfa_align --num_jobs 12 ../datasets/fire/positive/audio librispeech-lexicon.txt pretrained_models/english.zip ../datasets/fire/positive/alignment</div>
<div class="line">popd</div>
</div><!-- fragment --> The alignment can be found under <code>datasets/fire/positive/alignment</code> directory <div class="fragment"><div class="line">positive/</div>
<div class="line">└── alignment</div>
<div class="line">    ├── oovs_found.txt</div>
<div class="line">    ├── utterance_oovs.txt</div>
<div class="line">    └── audio</div>
<div class="line">        ├── common_voice_en_22465933.TextGrid</div>
<div class="line">        ├── common_voice_en_20995965.TextGrid</div>
<div class="line">        ...</div>
<div class="line">        └── common_voice_en_92432.TextGrid</div>
</div><!-- fragment --> The alignment file (<code>.TextGrid</code>) looks like the following <div class="fragment"><div class="line">...</div>
<div class="line">intervals [2]:</div>
<div class="line">    xmin = 0.750</div>
<div class="line">    xmax = 0.930</div>
<div class="line">    text = &quot;it&quot;</div>
<div class="line">intervals [3]:</div>
<div class="line">    xmin = 0.930</div>
<div class="line">    xmax = 1.590</div>
<div class="line">    text = &quot;closed&quot;</div>
<div class="line">intervals [4]:</div>
<div class="line">    xmin = 1.590</div>
<div class="line">    xmax = 2.270</div>
<div class="line">    text = &quot;down&quot;</div>
<div class="line">...</div>
</div><!-- fragment --></li>
<li>Generate some mock alignment for the negative set, where we don't care about alignment:</li>
</ol>
<div class="fragment"><div class="line">DATASET_PATH=datasets/fire/negative python -m training.run.attach_alignment --align-type stub</div>
</div><!-- fragment --><ol type="1">
<li>Use MFA to generate alignment for the positive set:</li>
</ol>
<div class="fragment"><div class="line">mfa_align datasets/fire/positive/audio eng.dict pretrained_models/english.zip output-folder</div>
</div><!-- fragment --><ol type="1">
<li>(Optional) Stitch vocab samples of aligned dataset to generate wakeword samples</li>
</ol>
<div class="fragment"><div class="line">VOCAB=&#39;[&quot;fire&quot;]&#39; INFERENCE_SEQUENCE=[0] python -m training.run.stitch_vocab_samples --aligned-dataset &quot;datasets/fire/positive&quot; --stitched-dataset &quot;data/fire-stitched&quot;</div>
</div><!-- fragment --> </div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.2
</small></address>
</body>
</html>
